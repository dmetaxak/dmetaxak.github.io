<!DOCTYPE html>
<html>
    <style>
        .navbar-fixed-top {
            margin-top: 0 !important;
            width:100% !important;
        }
    </style>

    <head>
        <title>
            Danaé Metaxa
        </title>

        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="http://localhost:4000/assets/css/style.css">
        <link rel="icon" href="http://localhost:4000/favicon.ico">
        <link href="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css" rel="stylesheet">
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

        
    </head>

    <body>
        <div class="container">
            <div class="col-md-12" role="main">
                        <p>Projects I&rsquo;ve worked on include gender and race representation in search algorithms (<em>in submission</em>), <a href="https://dl.acm.org/citation.cfm?id=3173574.3174188">stereotypes and inclusivity in web interfaces</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3359231">the role of search media in elections</a>, and <a href="https://dl.acm.org/citation.cfm?id=3274391">social capital during disaster events</a>.</p>

<p>In addition to academic publications, I&rsquo;ve written for a general audience on topics like <a href="https://www.theguardian.com/commentisfree/2018/sep/06/google-search-results-rigged-news-donald-trump">political bias in search results in <em>The Guardian</em></a>, and <a href="https://www.wired.co.uk/article/how-to-fix-facebook">social media sites and democracy in <em>Wired</em></a>.</p>

<p>Before my PhD, I graduated with dual degrees in Computer Science alongside Science, Technology, and Society at Brown University in 2015.</p>

<hr />

<h2>Research Highlights</h2>

<p>I have several ongoing threads of research, mainly focusing on bias and representation in algorithmic content, using a combination of computational and behavioral social science methods.</p>

<h3>Gender and Race Representation in Image Search Results</h3>

<center style="padding: 10px;">
<img src="media/author_race_P.png" alt="Search results for the query 'author' with most images of people of color." style="max-width: 85%;" />
</center>

<p><strong><a href="http://metaxa.net/content/papers/ImageSociety_2020.pdf">An Image of Society: Gender and Racial Representation and Impact in Image Search Results for Occupations</a></strong><br />
<strong>Danaë Metaxa</strong>, Michelle Gan, Su Goh, James Landay, and Jeff Hancock. <em>(ACM CSCW 2021)</em></p>

<p>Visual diversity has been the subject of studies in domains like psychology and advertising. But unlike the purposeful persuasive intent behind advertising, algorithmic content like search engine results are compiled automatically and spontaneously in response to user queries. Regardless of intent, the impact on users—say, a young person of color looking for information about their desired career and finding a sea of white faces—may still be substantial. <strong>Do image search results accurately reflect real-world gender and racial diversity? How does visual diversity influence users?</strong></p>

<p>In this project, currently in submission, we conducted an audit examining the results of Google Image queries for fifty common occupations, found that women and people of color were underrepresented relative to men and whites, and that the degree of this underrepresentation was not reflective of workforce participation. We then conducted a randomized controlled study exposing participants to a search results varying degrees of gender and racial diversity, finding that participants perceived occupations to be more inclusive when search results showed more women or people of color, and that participants’ interest in joining an occupation was greater when more people of color were represented. However, increasing the proportion of women actually decreased participant interest in some cases (perhaps an effect of perceived occupational feminization). We also examined the influence of participants’ own identities on their experience of image search results, finding that marginalized identity mediated participants’ expectation of being valued (e.g., greater representation of women was received positively by women participants but in some cases had a negative impact on men). Designing technology for inclusivity and belonging requires satisfying a complex and sometimes contradictory set of constraints; there is no silver bullet solution to make algorithms “fair” for all.</p>

<h3>Inclusive Web Design</h3>

<center style="padding: 10px;">
<img src="media/ambientbelonging_stimuli.png" alt="Two versions of an introductory course webpage" style="max-width: 85%;" />
</center>

<p><strong><a href="http://metaxa.net/content/papers/InclusiveDesign_CHI18.pdf">Gender-Inclusive Design: Belonging and Bias in Web Interfaces</a></strong><br />
<strong>Danaë Metaxa</strong>, Kelly Wang, James Landay, and Jeff Hancock. <em>(ACM CHI 2018)</em></p>

<p>Psychology theory suggests that people&rsquo;s ambient environments can cue stereotypes and influence their sense of belonging. Do digital spaces also impact self perception and choices? To answer this question, we ran a randomized controlled experiment to investigate, designing two different versions of a computer science course webpage altering only the aesthetics of the page but not its content. College-aged participants were either exposed to a course page with a neutral theme (i.e., images of trees, standard sans serif fonts) or one designed to evoke stereotypical ideas of computer science (i.e., star trek imagery, green text on a black background resembling a computer console). We found that, while men showed little preference for either website, women were negatively impacted by the stereotypical interface—they were less likely to feel they belonged in the course, less optimistic about their future performance, less interested in taking the course, and less interested in studying computer science at all. On the whole, women were 20% less likely to want to enroll in the course, a deterring effect of about twice that on men. This work uses gender bias as a case study supporting literature from psychology and translating it to a digital context; biases in online content can significantly impact users’ psychological sense of belonging, beliefs about themselves, and expected future behaviors.</p>

<h3>Algorithm Audits: Past, Present, and Best Practices</h3>

<p><em>Manuscript in preparation in collaboration with Joon Sung Park, Ronald E. Robertson, Karrie Karahalios, Christo Wilson, and Christian Sandvig.</em></p>

<p>Conducting a rigorous and effective algorithm audit like those I often deploy in my work entails legal and ethical challenges, as well as technical ones. I am currently leading a collaboration between leading algorithm audit researchers at Stanford, the University of Illinois at Urbana-Champaign, Northeastern University, and the University of Michigan to produce a journal article explaining the intellectual and scientific contributions of this important and versatile method, along with guidelines and best practices—technical, legal, and ethical—for conducting successful audit studies.</p>

<hr />

<h2>Other Recent Publications</h2>
<p>For a complete list of my academic publications, see my <a href="https://scholar.google.com/citations?user=6pA2wn4AAAAJ">Google Scholar page</a>.</p>

<p><a href="https://dl.acm.org/doi/fullHtml/10.1145/3313831.3376424">Random, Messy, Funny, Raw: Finstas as Intimate Reconfigurations of Social Media</a><br />
<em>Best Paper Honorable Mention</em><br />
Sijia Xiao, <strong>Danaë Metaxa</strong>, Joon Sung Park, Karrie Karahalios, and Niloufar Salehi <em>(ACM CHI 2020)</em></p>

<p><a href="https://dl.acm.org/doi/abs/10.1145/3359231">Search Media and Elections: A Longitudinal Investigation of Political Search Results in the 2018 U.S. Elections</a><br />
<strong>Danaë Metaxa</strong>, Joon Sung Park, James Landay, and Jeff Hancock (ACM CSCW 2019)</p>

<p><a href="https://reutersinstitute.politics.ox.ac.uk/our-research/glasnost-nine-ways-facebook-can-make-itself-better-forum-free-speech-and-democracy">Glasnost! Nine ways Facebook can make itself a better forum for free speech and democracy</a><br />
Timothy Garton Ash, Robert Gorwa, and <strong>Danaë Metaxa</strong> (Reuters Institute for the Study of Journalism, Oxford)</p>


            </div>
        </div>

        

        <!-- Google Analytics -->
        <script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-66737221-1');
ga('require', 'linkid', 'linkid.js');
ga('send', 'pageview');
        </script>
    </body>
</html>
